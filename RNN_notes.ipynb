{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_notes.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tmtakashi/machine_learning_notebooks/blob/master/RNN_notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "t_8iNdru2X8k",
        "colab_type": "code",
        "outputId": "3163dfbd-8234-4587-e229-c07262a0f9d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Wc6vQiTZ2ig0",
        "colab_type": "code",
        "outputId": "d2018655-7b44-41b4-ce2a-4148ee8adad5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "% cd /content/drive/My Drive/Colab Notebooks/fusic/RNN"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/fusic/RNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9hVxr_qrYNiw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNNまとめ"
      ]
    },
    {
      "metadata": {
        "id": "G5M6mVgyQTdJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Simple RNN"
      ]
    },
    {
      "metadata": {
        "id": "REX7UPQwYQ25",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### RNNレイヤの順伝搬\n",
        "- $\\bf h_t = \\tanh(\\bf h_{t-1}\\bf W_h + \\bf x_t\\bf W_x +\\bf b)$\n",
        "  - $\\bf W_x: $入力$\\bf x_t$を現時刻の出力$\\bf h_t$に変換する重み\n",
        "  - $\\bf W_h: $ひとつ前の時刻の出力$\\bf h_{t-1}$を現時刻の出力$\\bf h_t$に変換する重み\n",
        "  - $\\bf h_t$は隠れ状態ベクトル(hidden state vector)とよばれることが多い\n",
        "- stateful : 隠れ状態を維持し、順伝搬を断ち切ることなく伝搬させる\n",
        "  - 利点：ネットワークが小さく、学習時間が短い\n",
        "  - 欠点：データの周期性を反映するバッチサイズを選ぶ必要がある\n",
        "  - ほとんどの問題はstatelessで解ける。データが周期性を示す場合にはstatefulにする必要あり。"
      ]
    },
    {
      "metadata": {
        "id": "jQyl-SiWc76c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### RNNレイヤの逆伝搬\n",
        "- Backpropagation Through Time(BPTT)\n",
        "  - 長い時系列データを扱う際に計算リソース、メモリが足りなくなる\n",
        "- Truncated BPTT\n",
        "  - ネットワークを適当な長さで切る\n",
        "  - 小さなネットワークを複数つくり、それぞれで誤差逆伝搬法をおこなう\n",
        "  - 順伝搬のつながりは切断しない\n",
        "- ミニバッチ学習\n",
        "  - 通常のネットワークのように完全にランダムではダメ。シーケンシャルに与える必要がある。\n",
        "  - 例えば長さ1000の時系列データであれば$\\left(\n",
        "    \\begin{array}{ccc}\n",
        "      x_0 & x_1 & ... &x_9  \\\\\n",
        "      x_{500} & x_{501} & ... &x_{509} \n",
        "    \\end{array}\n",
        "  \\right)$\n",
        "  のように各バッチの開始位置をずらして入力"
      ]
    },
    {
      "metadata": {
        "id": "KJUWC1vxc5u-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RNN:\n",
        "    def __init__(self, Wx, Wh, b):\n",
        "        self.params = [Wx, Wh, b]\n",
        "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
        "        self.cache = None\n",
        "        \n",
        "    def forward(self, x, h_prev):\n",
        "        Wx, Wh, b = self.params\n",
        "        t = np.dot(h_prev, Wh) + np.dot(x, Wx) + b\n",
        "        h_next = np.tanh(t)\n",
        "        \n",
        "        self.cache = (x, h_prev, h_next)\n",
        "        return h_next\n",
        "    \n",
        "    def backward(self, dh_next):\n",
        "        Wx, Wh, b = self.params\n",
        "        x, h_prev, h_next = self.cache\n",
        "        \n",
        "        dt = dh_next * (1 - h_next **2)\n",
        "        db = np.sum(dt, axis=0)\n",
        "        dWh = np.dot(dt, Wh.T)\n",
        "        dh_prev = np.dot(dt, Wh.T)\n",
        "        dWx = np.dot(x.T, dt)\n",
        "        dx = np.dot(dt, Wx.T)\n",
        "        \n",
        "        self.grads[0][...] = dWx\n",
        "        self.grads[1][...] = dWh\n",
        "        self.grads[2][...] = db\n",
        "        \n",
        "        return dx, dh_prev"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fwhHdDl_wr6-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "シンプルな言語モデル\n",
        "- Embedding => RNN => Dense => Softmax"
      ]
    },
    {
      "metadata": {
        "id": "kMHZ6Qxe1xFo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  Simple RNNを用いたテキスト生成\n",
        "- 「不思議の国のアリス」(Alice in Wonderland)のテキストを用いて学習\n",
        "https://www.gutenberg.org/files/11/11-0.txt\n",
        "- 学習を高速にするために文字ベースの言語モデルを学習"
      ]
    },
    {
      "metadata": {
        "id": "8lNMl8Tk3Rec",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Activation, SimpleRNN\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "import codecs\n",
        "\n",
        "INPUT_FILE = './data/alice_in_wonderland.txt'\n",
        "\n",
        "with codecs.open(INPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "  lines = [line.strip().lower() for line in f  \n",
        "               if len(line) != 0]\n",
        "  text = \" \".join(lines)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jM4nZyEG5TKQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 文字のルックアップテーブルを作成\n",
        "chars = set(text)\n",
        "nb_chars = len(chars)\n",
        "char2index = dict((c, i) for i, c in enumerate(chars))\n",
        "index2char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZrUTd6E85jSV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 入力テキストおよびラベルテキストの作成\n",
        "SEQLEN = 10\n",
        "STEP = 1\n",
        "\n",
        "input_chars = []\n",
        "label_chars = []\n",
        "for i in range(0, len(text) - SEQLEN, STEP):\n",
        "  input_chars.append(text[i:i + SEQLEN])\n",
        "  label_chars.append(text[i + SEQLEN])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-a05l9Un5lNV",
        "colab_type": "code",
        "outputId": "2bc28739-d7e9-47bf-82af-e120963006f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "for input, label in zip(input_chars[:10], label_chars[:10]):\n",
        "  print(input, ' -> ', label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "﻿project g  ->  u\n",
            "project gu  ->  t\n",
            "roject gut  ->  e\n",
            "oject gute  ->  n\n",
            "ject guten  ->  b\n",
            "ect gutenb  ->  e\n",
            "ct gutenbe  ->  r\n",
            "t gutenber  ->  g\n",
            " gutenberg  ->  ’\n",
            "gutenberg’  ->  s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OEL68f6Y8krz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 入力テキストとラベルテキストのベクトル化、one-hotで表現\n",
        "X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n",
        "y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n",
        "for i, input_char in enumerate(input_chars):\n",
        "  for j, ch in enumerate(input_char):\n",
        "    X[i, j, char2index[ch]] = 1\n",
        "  y[i, char2index[label_chars[i]]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D0ktdMHi-OhD",
        "colab_type": "code",
        "outputId": "b48ae761-9861-416e-c9d6-ebde925d20db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2567
        }
      },
      "cell_type": "code",
      "source": [
        "HIDDEN_SIZE = 128\n",
        "BATCH_SIZE = 128\n",
        "NUM_ITERATIONS = 25\n",
        "NUM_EPOCHS_PER_ITERATION = 1\n",
        "NUM_PREDS_PER_EPOCH =100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(HIDDEN_SIZE, return_sequences=False,  # 単一の文字を返す\n",
        "                   input_shape=(SEQLEN, nb_chars),\n",
        "                   unroll=True)) # TensorFlowバックエンドのパフォーマンス向上\n",
        "model.add(Dense(nb_chars))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\n",
        "\n",
        "for iteration in range(NUM_ITERATIONS):\n",
        "  print(\"=\" * 50)\n",
        "  print(\"Iteration #: %d\" % (iteration))\n",
        "  model.fit(X, y, batch_size=BATCH_SIZE,\n",
        "           epochs=NUM_EPOCHS_PER_ITERATION)\n",
        "  \n",
        "  test_idx = np.random.randint(len(input_chars))\n",
        "  test_chars = input_chars[test_idx]\n",
        "  print(\"Generating from seed: %s\" % (test_chars))\n",
        "  print(test_chars, end=\"\")\n",
        "  for i in range(NUM_PREDS_PER_EPOCH):\n",
        "    Xtest = np.zeros((1, SEQLEN, nb_chars))\n",
        "    for i, ch in enumerate(test_chars):\n",
        "      Xtest[0, i, char2index[ch]] = 1\n",
        "    pred = model.predict(Xtest, verbose=0)[0]\n",
        "    ypred = index2char[np.argmax(pred)]\n",
        "    print(ypred, end=\"\")\n",
        "    test_chars = test_chars[1:] + ypred\n",
        "  print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Iteration #: 0\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 14s 88us/step - loss: 2.3783\n",
            "Generating from seed: e gryphon \n",
            "e gryphon the mand an the meree so the the soute the she sout an the maste so the soo to the soo to the soo to\n",
            "==================================================\n",
            "Iteration #: 1\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 8s 49us/step - loss: 2.0639\n",
            "Generating from seed: change, bu\n",
            "change, but the ground the said the dont ou do the the said the dont ou do the the said the dont ou do the the\n",
            "==================================================\n",
            "Iteration #: 2\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 8s 49us/step - loss: 1.9544\n",
            "Generating from seed: ed tone.  \n",
            "ed tone.  ‘the was she was she was she was she was she was she was she was she was she was she was she was she\n",
            "==================================================\n",
            "Iteration #: 3\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 8s 49us/step - loss: 1.8713\n",
            "Generating from seed: cated also\n",
            "cated also the was so don the grople she had so don the grople she had so don the grople she had so don the gr\n",
            "==================================================\n",
            "Iteration #: 4\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 8s 50us/step - loss: 1.8055\n",
            "Generating from seed: ese effort\n",
            "ese efforted the could she cand alice the cand with the cand with the cand with the cand with the cand with th\n",
            "==================================================\n",
            "Iteration #: 5\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 8s 50us/step - loss: 1.7511\n",
            "Generating from seed: t get them\n",
            "t get them she could not to betore the routhe to her in a the the reat do a cand it a mand the catersting the \n",
            "==================================================\n",
            "Iteration #: 6\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 8s 50us/step - loss: 1.7047\n",
            "Generating from seed: ’ll take n\n",
            "’ll take not in a don’t and alice was she was she was she was she was she was she was she was she was she was \n",
            "==================================================\n",
            "Iteration #: 7\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 8s 49us/step - loss: 1.6655\n",
            "Generating from seed: eaded!’ sa\n",
            "eaded!’ said the mock turtle the mock turtle the mock turtle the mock turtle the mock turtle the mock turtle t\n",
            "==================================================\n",
            "Iteration #: 8\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 8s 49us/step - loss: 1.6307\n",
            "Generating from seed: ht alice; \n",
            "ht alice; ‘and the mock turtle she said the mock turtle she said the mock turtle she said the mock turtle she \n",
            "==================================================\n",
            "Iteration #: 9\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 8s 50us/step - loss: 1.6021\n",
            "Generating from seed: l i’ve fin\n",
            "l i’ve fing and the mouse for a murtly was a long the project gutenberg-tm like the project gutenberg-tm like \n",
            "==================================================\n",
            "Iteration #: 10\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 8s 49us/step - loss: 1.5761\n",
            "Generating from seed:  whole thi\n",
            " whole thing i say the mouse the mouse the mouse the mouse the mouse the mouse the mouse the mouse the mouse t\n",
            "==================================================\n",
            "Iteration #: 11\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 8s 49us/step - loss: 1.5537\n",
            "Generating from seed: he march h\n",
            "he march hare the mouse the mouse the mouse the mouse the mouse the mouse the mouse the mouse the mouse the mo\n",
            "==================================================\n",
            "Iteration #: 12\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 8s 50us/step - loss: 1.5344\n",
            "Generating from seed: t was very\n",
            "t was very course for the mouse of the mock turtle so must be go down a this the mock turtle so must be go dow\n",
            "==================================================\n",
            "Iteration #: 13\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 8s 50us/step - loss: 1.5169\n",
            "Generating from seed: sides of t\n",
            "sides of the mouse they was a little so down at the mouse they was a little so down at the mouse they was a li\n",
            "==================================================\n",
            "Iteration #: 14\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 8s 49us/step - loss: 1.5015\n",
            "Generating from seed:  paw, ‘liv\n",
            " paw, ‘live you do she was said to herself have you think you do she was said to herself have you think you do\n",
            "==================================================\n",
            "Iteration #: 15\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 8s 49us/step - loss: 1.4869\n",
            "Generating from seed: ttle birds\n",
            "ttle birds and down and the gryphon, and the gryphon, and the gryphon, and the gryphon, and the gryphon, and t\n",
            "==================================================\n",
            "Iteration #: 16\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 8s 49us/step - loss: 1.4750\n",
            "Generating from seed: o thin--an\n",
            "o thin--and the project gutenberg-tm electronic works it was so the poor one of the white rabbit alice to hers\n",
            "==================================================\n",
            "Iteration #: 17\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 8s 49us/step - loss: 1.4640\n",
            "Generating from seed: er to hers\n",
            "er to herself sto the door of the mouse don’t get to get in a stoon as it was any harde a caterpillar the cate\n",
            "==================================================\n",
            "Iteration #: 18\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 8s 49us/step - loss: 1.4525\n",
            "Generating from seed: ing his vo\n",
            "ing his voice of the mouse of the project gutenberg-tm works and the mock turtle so she was so she was so she \n",
            "==================================================\n",
            "Iteration #: 19\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 8s 49us/step - loss: 1.4427\n",
            "Generating from seed: ked out a \n",
            "ked out a court goon was the mock turtle say to see the way out of the white rabbit of the court goon was the \n",
            "==================================================\n",
            "Iteration #: 20\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 8s 49us/step - loss: 1.4335\n",
            "Generating from seed: ape doesn’\n",
            "ape doesn’t to not and the streating it was states the streating it was states the streating it was states the\n",
            "==================================================\n",
            "Iteration #: 21\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 8s 49us/step - loss: 1.4260\n",
            "Generating from seed: ys get int\n",
            "ys get into the king as the white rabbit began to be a little going to be the parate and what a growled at the\n",
            "==================================================\n",
            "Iteration #: 22\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 8s 50us/step - loss: 1.4176\n",
            "Generating from seed:  the other\n",
            " the other the dormouse she took the reater of the mouse of the mouse of the mouse of the mouse of the mouse o\n",
            "==================================================\n",
            "Iteration #: 23\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 8s 49us/step - loss: 1.4102\n",
            "Generating from seed:  far,’ sai\n",
            " far,’ said the caterpillar the look out of the court, the court, the court, the court, the court, the court, \n",
            "==================================================\n",
            "Iteration #: 24\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 8s 50us/step - loss: 1.4037\n",
            "Generating from seed: e caterpil\n",
            "e caterpillar the known at her she was stall have to the gryphon, ‘i wonder what i shall for the soldiers to h\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ks5GfMjn81q4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- RNNの出力次元は実験してチューニングする必要がある\n",
        "  - 次元が小さすぎると自然なテキストを生成できない\n",
        "  - 次元が大きすぎると学習コストがかかる"
      ]
    },
    {
      "metadata": {
        "id": "bX-l0ZEhTal1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## ゲート付きRNN\n",
        "- Simple RNNは性能があまり良くない\n",
        "  - 時系列データの長期の依存関係をうまく学習できないため\n",
        "- 現在ではLSTMやGRUが使われる\n",
        "  - 単にRNNというときはLSTMを指すときが多い\n",
        "  - 「ゲート」と呼ばれる仕組みで時系列データの長期的な依存関係を学習できるようにする\n",
        "\n",
        "### 勾配消失・勾配爆発\n",
        "- 例文：\"Tom was watching TV in his room. Mary came into the room. Mary said hi to [ ? ]\"\n",
        "- 逆伝搬する際に勾配が途中で弱まると重みが更新されなくなる\n",
        "  - 原因\n",
        "    1. tanhノードを逆伝搬すると、微分が0~1の値しか取らない。-> 時間が長くなればなるほど勾配がどんどん小さくなる。\n",
        "      - ReLUを用いて性能向上した例もある。\n",
        "        - Improving performance of recurrent neural network with relu nonlinearity https://arxiv.org/pdf/1511.03771.pdf\n",
        "    2. Matmul（行列の積）ノードの逆伝搬を計算する際は$dhW^T_h \\cdots W^T_h$と、毎回同じ重みを掛け算していく。\n",
        "      - http://www.wildml.com/2015/10/recurrent-neural-networks-tutorial-part-3-backpropagation-through-time-and-vanishing-gradients/"
      ]
    },
    {
      "metadata": {
        "id": "LsZulue0TYg5",
        "colab_type": "code",
        "outputId": "c4188600-afe8-4296-939a-68f7347c1475",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "cell_type": "code",
      "source": [
        "# 20回Whを掛け算していくとどうなるか？\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "N = 2 # ミニバッチサイズ\n",
        "H = 3 #隠れ状態ベクトルの次元数\n",
        "T = 20 # 時系列データの長さ\n",
        "\n",
        "dh = np.ones((N, H))\n",
        "np.random.seed(3)\n",
        "Wh = np.random.randn(H, H)\n",
        "\n",
        "norm_list = []\n",
        "for t in range(T):\n",
        "  dh = np.dot(dh, Wh.T)\n",
        "  norm = np.sqrt(np.sum(dh**2)) / N\n",
        "  norm_list.append(norm)\n",
        "\n",
        "plt.plot(norm_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "249.495615421267\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f35be5cf208>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFKCAYAAADMuCxnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f35be601eb8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "lA3ZCRoXZDyE",
        "colab_type": "code",
        "outputId": "34ae5050-5250-4f41-c001-270c9866d073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "cell_type": "code",
      "source": [
        "# 20回Whを掛け算していくとどうなるか？\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "N = 2 # ミニバッチサイズ\n",
        "H = 3 #隠れ状態ベクトルの次元数\n",
        "T = 20 # 時系列データの長さ\n",
        "\n",
        "dh = np.ones((N, H))\n",
        "np.random.seed(3)\n",
        "Wh = 0.5 * np.random.randn(H, H) # 初期値を半分にしてみる\n",
        "\n",
        "norm_list = []\n",
        "for t in range(T):\n",
        "  dh = np.dot(dh, Wh.T)\n",
        "  norm = np.sqrt(np.sum(dh**2)) / N\n",
        "  norm_list.append(norm)\n",
        "\n",
        "plt.plot(norm_list)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f35bbc8a710>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f35bbd78a58>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "EUDc2xCiaFZe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 勾配爆発・消失への対策\n",
        "- 勾配爆発\n",
        "  - 勾配クリッピング\n",
        "  - $\\begin{eqnarray}\n",
        "    if  ||\\hat g|| \\geq threshold:\\\\\n",
        "      \\hat g = \\frac{threshold}{||\\hat g||}\\hat g\n",
        "   \\end{eqnarray}$\n",
        "- 勾配消失\n",
        "  - LSTM, GRU"
      ]
    },
    {
      "metadata": {
        "id": "4O4Ex5LsckHr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### LSTM\n",
        "- http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
        "- 活性化関数\n",
        "  - ゲート：sigmoid (0~1、どれだけ通すか)\n",
        "  - 情報 ：tanh (-1~1、情報を圧縮)\n",
        "- 記憶セル $\\bf c$\n",
        "  - LSTMレイヤ内で受け渡しをする\n",
        "  - 外部からは見えない\n",
        "  - 隠れ状態$\\bf h$は別のレイヤにも受け渡しをする\n",
        "- outputゲート\n",
        "  - 次の隠れ状態$\\bf h_t$の出力を司る\n",
        "  - 入力$\\bf x_t$と前の隠れ状態$\\bf h_{t-1}$から求める\n",
        "    - $\\bf o = \\sigma (\\bf x_t\\bf W^{(o)}_x + \\bf h_{t-1}\\bf W^{(o)}_h + \\bf b^{(o)})$\n",
        "    - $\\sigma$ :シグモイド関数\n",
        "  - $h_t = \\bf o \\odot \\tanh(\\bf c_t)$\n",
        "- forgetゲート\n",
        "  - 記憶セルに対して「何を忘れるか」を明示的に指示\n",
        "  - $\\bf c_{t-1}$の記憶から不要な記憶を忘れさせる\n",
        "  - $\\bf f = \\sigma (\\bf x_t\\bf W^{(f)}_x + \\bf h_{t-1}\\bf W^{(f)}_h + \\bf b^{(f)})$\n",
        "- 新しい記憶セルに付加する情報\n",
        "  - 「情報」を付加 => tanhを使用\n",
        "  - $\\bf g = \\tanh (\\bf x_t\\bf W^{(g)}_x + \\bf h_{t-1}\\bf W^{(g)}_h + \\bf b^{(g)})$\n",
        "- inputゲート\n",
        "  - $\\bf g$に対してのゲート\n",
        "  - $\\bf i = \\sigma (\\bf x_t\\bf W^{(i)}_x + \\bf h_{t-1}\\bf W^{(i)}_h + \\bf b^{(i)})$\n",
        "  - $\\bf c_t = \\bf f \\odot \\bf c_{t-1}+ \\bf g \\odot \\bf i$\n",
        "- 勾配消失を起こさない理由\n",
        "  - 記憶セルに注目\n",
        "    - 加算ノードは上流からの勾配をそのまま伝えるだけ\n",
        "    - forgetゲートが記憶セルの各要素の重要性をコントロールしている（要素ごとの積によるもの）\n",
        "      - 忘れるべき要素の勾配は小さく、覚えるべき要素の勾配はそのまま伝搬"
      ]
    },
    {
      "metadata": {
        "id": "S4N24ywooTKy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####  LSTMを用いたテキスト生成\n",
        "- Simple RNNと比べるとlossが若干下がっている。\n"
      ]
    },
    {
      "metadata": {
        "id": "096yrjjrZWeV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Activation, LSTM\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "import codecs\n",
        "\n",
        "INPUT_FILE = './data/alice_in_wonderland.txt'\n",
        "\n",
        "with codecs.open(INPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "  lines = [line.strip().lower() for line in f  \n",
        "               if len(line) != 0]\n",
        "  text = \" \".join(lines)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qZuZ0bk9n3yw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 文字のルックアップテーブルを作成\n",
        "chars = set(text)\n",
        "nb_chars = len(chars)\n",
        "char2index = dict((c, i) for i, c in enumerate(chars))\n",
        "index2char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Dd4YmYYn65-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 入力テキストおよびラベルテキストの作成\n",
        "SEQLEN = 10\n",
        "STEP = 1\n",
        "\n",
        "input_chars = []\n",
        "label_chars = []\n",
        "for i in range(0, len(text) - SEQLEN, STEP):\n",
        "  input_chars.append(text[i:i + SEQLEN])\n",
        "  label_chars.append(text[i + SEQLEN])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BfBf61d1n-Kl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 入力テキストとラベルテキストのベクトル化、one-hotで表現\n",
        "X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n",
        "y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n",
        "for i, input_char in enumerate(input_chars):\n",
        "  for j, ch in enumerate(input_char):\n",
        "    X[i, j, char2index[ch]] = 1\n",
        "  y[i, char2index[label_chars[i]]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NAdt4mPloCRx",
        "colab_type": "code",
        "outputId": "a200429a-1b23-492d-fdb9-bfba210fd52d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2567
        }
      },
      "cell_type": "code",
      "source": [
        "HIDDEN_SIZE = 128\n",
        "BATCH_SIZE = 128\n",
        "NUM_ITERATIONS = 25\n",
        "NUM_EPOCHS_PER_ITERATION = 1\n",
        "NUM_PREDS_PER_EPOCH =100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(HIDDEN_SIZE, return_sequences=False,  # 単一の文字を返す\n",
        "                   input_shape=(SEQLEN, nb_chars),\n",
        "                   unroll=True)) # TensorFlowバックエンドのパフォーマンス向上\n",
        "model.add(Dense(nb_chars))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\n",
        "\n",
        "for iteration in range(NUM_ITERATIONS):\n",
        "  print(\"=\" * 50)\n",
        "  print(\"Iteration #: %d\" % (iteration))\n",
        "  model.fit(X, y, batch_size=BATCH_SIZE,\n",
        "           epochs=NUM_EPOCHS_PER_ITERATION)\n",
        "  \n",
        "  test_idx = np.random.randint(len(input_chars))\n",
        "  test_chars = input_chars[test_idx]\n",
        "  print(\"Generating from seed: %s\" % (test_chars))\n",
        "  print(test_chars, end=\"\")\n",
        "  for i in range(NUM_PREDS_PER_EPOCH):\n",
        "    Xtest = np.zeros((1, SEQLEN, nb_chars))\n",
        "    for i, ch in enumerate(test_chars):\n",
        "      Xtest[0, i, char2index[ch]] = 1\n",
        "    pred = model.predict(Xtest, verbose=0)[0]\n",
        "    ypred = index2char[np.argmax(pred)]\n",
        "    print(ypred, end=\"\")\n",
        "    test_chars = test_chars[1:] + ypred\n",
        "  print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Iteration #: 0\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 23s 141us/step - loss: 2.4961\n",
            "Generating from seed: inst it, t\n",
            "inst it, the the the the the the the the the the the the the the the the the the the the the the the the the t\n",
            "==================================================\n",
            "Iteration #: 1\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 20s 121us/step - loss: 2.0270\n",
            "Generating from seed:  be no cha\n",
            " be no chat in the made the made the made the made the made the made the made the made the made the made the m\n",
            "==================================================\n",
            "Iteration #: 2\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 20s 121us/step - loss: 1.8330\n",
            "Generating from seed: dict,’ the\n",
            "dict,’ the gat in a little sald the project gutenberg-t me the read the project gutenberg-t me the read the pr\n",
            "==================================================\n",
            "Iteration #: 3\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 20s 121us/step - loss: 1.7100\n",
            "Generating from seed: pleasing t\n",
            "pleasing to the was a little the was a little the was a little the was a little the was a little the was a lit\n",
            "==================================================\n",
            "Iteration #: 4\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 20s 121us/step - loss: 1.6207\n",
            "Generating from seed: the poor l\n",
            "the poor little with the project gutenberg-tm electronice of the ware and the door and the ware and the door a\n",
            "==================================================\n",
            "Iteration #: 5\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 19s 120us/step - loss: 1.5499\n",
            "Generating from seed: nly hear w\n",
            "nly hear was so the mouse of the seated to her head to see her head to see her head to see her head to see her\n",
            "==================================================\n",
            "Iteration #: 6\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 19s 119us/step - loss: 1.4912\n",
            "Generating from seed: did it so \n",
            "did it so the was a little stood and the work and the work and the work and the work and the work and the work\n",
            "==================================================\n",
            "Iteration #: 7\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 19s 119us/step - loss: 1.4420\n",
            "Generating from seed: h one eye;\n",
            "h one eye; ‘i don’t the dormouse of the the shearted to herself and she had not to her head to her head to her\n",
            "==================================================\n",
            "Iteration #: 8\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 19s 120us/step - loss: 1.4002\n",
            "Generating from seed: going off \n",
            "going off the court, ‘i say it was a little before and the works with the project gutenberg-tm electronic work\n",
            "==================================================\n",
            "Iteration #: 9\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 19s 120us/step - loss: 1.3640\n",
            "Generating from seed: s in its h\n",
            "s in its had to see so the cat spoke the same this sime they all the say the caterpillar some the caterpillar \n",
            "==================================================\n",
            "Iteration #: 10\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 19s 120us/step - loss: 1.3312\n",
            "Generating from seed:  raven lik\n",
            " raven like the looked at the project gutenberg-tm electronic work in a low the party down a little she had no\n",
            "==================================================\n",
            "Iteration #: 11\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 19s 120us/step - loss: 1.3029\n",
            "Generating from seed: et you fin\n",
            "et you find you think you have to be she her hands of the cat the little golden with a little been and the dor\n",
            "==================================================\n",
            "Iteration #: 12\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 19s 120us/step - loss: 1.2768\n",
            "Generating from seed:  a great i\n",
            " a great into its that it was a little beling at the sempents to the convers to be a little beling at the semp\n",
            "==================================================\n",
            "Iteration #: 13\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 20s 120us/step - loss: 1.2532\n",
            "Generating from seed:  of them a\n",
            " of them all the things and she had to the mock turtle said to herself as she had to the mock turtle said to h\n",
            "==================================================\n",
            "Iteration #: 14\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 20s 120us/step - loss: 1.2318\n",
            "Generating from seed:  sea.’  ‘i\n",
            " sea.’  ‘i can’t got to the door of her head the dormouse she had never have you are all the reason of the cat\n",
            "==================================================\n",
            "Iteration #: 15\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 19s 120us/step - loss: 1.2114\n",
            "Generating from seed: h the stra\n",
            "h the strange about as she said to herself, ‘and the work in any repeat she was a little been and the sort of \n",
            "==================================================\n",
            "Iteration #: 16\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 19s 120us/step - loss: 1.1932\n",
            "Generating from seed: ral way.  \n",
            "ral way.  ‘i won’t you, won’t you, won’t you, won’t you, won’t you, won’t you, won’t you, won’t you, won’t you\n",
            "==================================================\n",
            "Iteration #: 17\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 19s 120us/step - loss: 1.1753\n",
            "Generating from seed: d so these\n",
            "d so these came the cook till she had got because the door of the cook till she had got because the door of th\n",
            "==================================================\n",
            "Iteration #: 18\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 19s 120us/step - loss: 1.1583\n",
            "Generating from seed: ng any par\n",
            "ng any party did not any party did not any party did not any party did not any party did not any party did not\n",
            "==================================================\n",
            "Iteration #: 19\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 19s 120us/step - loss: 1.1430\n",
            "Generating from seed: gs--everyt\n",
            "gs--everything that she was a little best concert to be one of the court, and the words ‘and the words ‘and th\n",
            "==================================================\n",
            "Iteration #: 20\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 19s 120us/step - loss: 1.1285\n",
            "Generating from seed: f course n\n",
            "f course not at all a low to the three gardeners with the permossion of the court, and was going to herself, ‘\n",
            "==================================================\n",
            "Iteration #: 21\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 19s 120us/step - loss: 1.1144\n",
            "Generating from seed: eers and e\n",
            "eers and engring the cook to the project gutenberg-tm electronic works in a thring again, and the project gute\n",
            "==================================================\n",
            "Iteration #: 22\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 19s 119us/step - loss: 1.1009\n",
            "Generating from seed: that would\n",
            "that would be on the soldiers works with a telick to the conversation and a pain of course, and alice was soon\n",
            "==================================================\n",
            "Iteration #: 23\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 19s 120us/step - loss: 1.0870\n",
            "Generating from seed: ar and lef\n",
            "ar and left off when she had not at all the things and she had not at all the things and she had not at all th\n",
            "==================================================\n",
            "Iteration #: 24\n",
            "Epoch 1/1\n",
            "162739/162739 [==============================] - 19s 119us/step - loss: 1.0749\n",
            "Generating from seed: hought dec\n",
            "hought decived to herself, ‘i was a little shriek for other sharply would you have no hear to herself, ‘i was \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CVS9EgXoxY6H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### LSTMで文章分類\n",
        "-  ライブドアニュースコーパスを使用https://www.rondhuit.com/download.html#ldcc\n"
      ]
    },
    {
      "metadata": {
        "id": "E4QIpr9axk98",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget  https://www.rondhuit.com/download/ldcc-20140209.tar.gz\n",
        "!tar -zxvf ldcc-20140209.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B7PRKkoKxwjJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import codecs\n",
        "from sklearn.model_selection import train_test_split\n",
        " \n",
        "category_dirs = ['it-life-hack', 'movie-enter', 'sports-watch']\n",
        " \n",
        "X = []\n",
        "y =[]\n",
        "for index, category in enumerate(category_dirs):\n",
        "    files = Path('./text/{}'.format(category)).glob('*.txt')\n",
        "    for file in files:\n",
        "        with codecs.open(str(file), \"r\") as txt_data:\n",
        "          lines = txt_data.readlines()\n",
        "          X.append(str(lines[2]).replace('【Sports Watch】', '').rstrip())\n",
        "          y.append(index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VT9TV2KcGDT5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt install aptitude\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "!pip install mecab-python3==0.7\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uM7wRdbRJ2xJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#https://www.pytry3g.com/entry/2018/03/16/203414#2-%E5%8D%98%E8%AA%9E%E8%BE%9E%E6%9B%B8%E3%82%92%E4%BD%9C%E3%82%8A%E5%AD%A6%E7%BF%92%E3%83%87%E3%83%BC%E3%82%BF%E3%82%92%E3%82%A4%E3%83%B3%E3%83%87%E3%83%83%E3%82%AF%E3%82%B9%E3%81%AB%E5%A4%89%E6%8F%9B%E3%81%99%E3%82%8B\n",
        "\n",
        "from text_encoder import JapaneseTextEncoder\n",
        "\n",
        "encoder = JapaneseTextEncoder(X, maxlen=100, padding=True)\n",
        "encoder.build()\n",
        "\n",
        "x_id = encoder.dataset\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C9CKd0EiV-hr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_id = np.array(x_id).\n",
        "y = to_categorical(np.array(y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N0iScoxovoKC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_id, y, test_size=0.2, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yRPYG3w43vsM",
        "colab_type": "code",
        "outputId": "da9bb241-2cef-4abf-e57e-f2eeea796718",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2114, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "metadata": {
        "id": "agRm3WDEN9_K",
        "colab_type": "code",
        "outputId": "d5e9f01a-ab0c-4c37-f0d0-0bb269e5ff93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "embedding_matrix = np.zeros((len(encoder.word2id), 100))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(\n",
        "        input_dim=embedding_matrix.shape[0], \n",
        "        output_dim=embedding_matrix.shape[1],\n",
        "        mask_zero=True))\n",
        "model.add(LSTM(32, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32,validation_data=(x_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_32 (Embedding)     (None, None, 100)         794500    \n",
            "_________________________________________________________________\n",
            "lstm_43 (LSTM)               (None, None, 32)          17024     \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, None, 32)          0         \n",
            "_________________________________________________________________\n",
            "lstm_44 (LSTM)               (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 819,943\n",
            "Trainable params: 819,943\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 2114 samples, validate on 529 samples\n",
            "Epoch 1/10\n",
            "2114/2114 [==============================] - 42s 20ms/step - loss: 0.8794 - acc: 0.5965 - val_loss: 0.4703 - val_acc: 0.8299\n",
            "Epoch 2/10\n",
            "2114/2114 [==============================] - 36s 17ms/step - loss: 0.1966 - acc: 0.9465 - val_loss: 0.2398 - val_acc: 0.9187\n",
            "Epoch 3/10\n",
            "2114/2114 [==============================] - 36s 17ms/step - loss: 0.0418 - acc: 0.9953 - val_loss: 0.3093 - val_acc: 0.9130\n",
            "Epoch 4/10\n",
            "2114/2114 [==============================] - 36s 17ms/step - loss: 0.0217 - acc: 0.9981 - val_loss: 0.2656 - val_acc: 0.9376\n",
            "Epoch 5/10\n",
            "2114/2114 [==============================] - 36s 17ms/step - loss: 0.0124 - acc: 0.9995 - val_loss: 0.3016 - val_acc: 0.9357\n",
            "Epoch 6/10\n",
            "2114/2114 [==============================] - 36s 17ms/step - loss: 0.0093 - acc: 0.9995 - val_loss: 0.3280 - val_acc: 0.9357\n",
            "Epoch 7/10\n",
            "2114/2114 [==============================] - 36s 17ms/step - loss: 0.0069 - acc: 0.9995 - val_loss: 0.3333 - val_acc: 0.9376\n",
            "Epoch 8/10\n",
            "2114/2114 [==============================] - 36s 17ms/step - loss: 0.0090 - acc: 0.9991 - val_loss: 0.3894 - val_acc: 0.9319\n",
            "Epoch 9/10\n",
            "2114/2114 [==============================] - 36s 17ms/step - loss: 0.0085 - acc: 0.9995 - val_loss: 0.3998 - val_acc: 0.9338\n",
            "Epoch 10/10\n",
            "2114/2114 [==============================] - 36s 17ms/step - loss: 0.0059 - acc: 0.9995 - val_loss: 0.4071 - val_acc: 0.9319\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f42324a79b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "metadata": {
        "id": "dnbkWq__r35M",
        "colab_type": "code",
        "outputId": "88a20e76-b53f-4d38-cb8b-4cfd10688132",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1853
        }
      },
      "cell_type": "code",
      "source": [
        "# 誤った予測\n",
        "val_pred = np.argmax(model.predict(x_val), axis=1)\n",
        "pred_fails = np.where(val_pred != np.argmax(y_val, axis=1))[0]\n",
        "for pred_fail in pred_fails:\n",
        "  print(encoder.decode(x_val[pred_fail]))\n",
        "  print('予測: ', category_dirs[val_pred[pred_fail]])\n",
        "  print('正解: ', category_dirs[np.argmax(y_val, axis=1)[pred_fail]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15歳の天才空手美少女が映画デビュー「気分はシンデレラ」\n",
            "予測:  sports-watch\n",
            "正解:  movie-enter\n",
            "こんな目で娘に見つめられたい！娘と父の美しすぎる蜜月久保和範写真展「恋人」\n",
            "予測:  sports-watch\n",
            "正解:  it-life-hack\n",
            "原著作者のクレジットを表示し、ニュース記事の改変をしないことを条件に、記事全文を\n",
            "予測:  sports-watch\n",
            "正解:  movie-enter\n",
            "“世界一過激なコメディアン”がビキニ美女とカンヌを“独裁”\n",
            "予測:  sports-watch\n",
            "正解:  movie-enter\n",
            "雨上がり決死隊の宮迫が、息子と対決\n",
            "予測:  sports-watch\n",
            "正解:  movie-enter\n",
            "中田英寿、被災地の子供たちにクリスマスプレゼント\n",
            "予測:  sports-watch\n",
            "正解:  movie-enter\n",
            "国内主要空港でのサポートを拡充！テレコムスクェア新オープン＆リニューアル！\n",
            "予測:  sports-watch\n",
            "正解:  it-life-hack\n",
            "60歳のリーアム・ニーソンが大自然に挑む！　全米初登場1位を獲得した話題作の特別映像が公開\n",
            "予測:  it-life-hack\n",
            "正解:  movie-enter\n",
            "西田敏行も思わず涙ぐむ「父から娘」への手紙\n",
            "予測:  sports-watch\n",
            "正解:  movie-enter\n",
            "吉澤ひとみが新チーム結成「今、大事にしなきゃいけない人」\n",
            "予測:  sports-watch\n",
            "正解:  movie-enter\n",
            "大手飲料メーカーが繰り広げる“遼君争奪戦”とは？\n",
            "予測:  movie-enter\n",
            "正解:  sports-watch\n",
            "開会式は「五輪のマークが出てきて、それがとんでもないことになる」!?\n",
            "予測:  movie-enter\n",
            "正解:  sports-watch\n",
            "何でもありか？なでしこジャパンの試合に“職権乱用”コマーシャル\n",
            "予測:  sports-watch\n",
            "正解:  movie-enter\n",
            "ジャガーとトラが対決！「奇跡体験！アンビリバボー」も驚く、あり得ない体験\n",
            "予測:  it-life-hack\n",
            "正解:  movie-enter\n",
            "あの「ペルソナ」シリーズのライブイベントが全国劇場で\n",
            "予測:  sports-watch\n",
            "正解:  movie-enter\n",
            "女だらけの地球防衛隊「チームＵ」にAKB48選抜メンバーが就任\n",
            "予測:  sports-watch\n",
            "正解:  movie-enter\n",
            "長澤まさみ似の美少女ダイバー・馬淵優佳が日本一に【画像アリ】\n",
            "予測:  movie-enter\n",
            "正解:  sports-watch\n",
            "その建物に歴史あり！　建物の名称を表わす“建て書き”写真の数々\n",
            "予測:  movie-enter\n",
            "正解:  it-life-hack\n",
            "15歳の天才空手美少女「デビュー作を見てもらえることにワクワクどきどき」\n",
            "予測:  sports-watch\n",
            "正解:  movie-enter\n",
            "サッチーvsミッチー実現なるか？プロレス団体名は「SMAP」に？？\n",
            "予測:  it-life-hack\n",
            "正解:  sports-watch\n",
            "実際にあった驚きの脱獄事件！　リーアム・ニーソンが脱獄術を語る\n",
            "予測:  it-life-hack\n",
            "正解:  movie-enter\n",
            "新潟×川崎で2年連続のハプニング、レインガンが観客席へ\n",
            "予測:  movie-enter\n",
            "正解:  sports-watch\n",
            "レノボ、プロゴルファーの斉藤愛璃選手とオフィシャル・スポンサーシップ契約を締結\n",
            "予測:  sports-watch\n",
            "正解:  it-life-hack\n",
            "親友でもありライバルでもある2人の美人スイマー\n",
            "予測:  it-life-hack\n",
            "正解:  sports-watch\n",
            "Ultrabookに強力なライバル！女性がラクに持ち運べる、エイサーのノートPCが凄い\n",
            "予測:  movie-enter\n",
            "正解:  it-life-hack\n",
            "周辺地域の情報をゲット「ご当地ニュースbyロケタッチ新聞」リリース\n",
            "予測:  movie-enter\n",
            "正解:  it-life-hack\n",
            "いま話題の人気アイドルたちが、一夜限りの大共演\n",
            "予測:  sports-watch\n",
            "正解:  movie-enter\n",
            "「さわお」×「わさお」が奇跡の対面\n",
            "予測:  sports-watch\n",
            "正解:  movie-enter\n",
            "ヤラセ番組のつもりが本当の恐怖に！　動画サイトで再生回数2,100万回突破の超常現象映像\n",
            "予測:  it-life-hack\n",
            "正解:  movie-enter\n",
            "権田のインタビューに「さらし者かよ」の声\n",
            "予測:  movie-enter\n",
            "正解:  sports-watch\n",
            "子供がなりたい職業とは？\n",
            "予測:  movie-enter\n",
            "正解:  sports-watch\n",
            "シーズン5・解説−怪物との戦い、そのピーク−\n",
            "予測:  sports-watch\n",
            "正解:  movie-enter\n",
            "「本人そっくり」と世界中で話題の“鉄の女”、ポスター画像と予告編が解禁\n",
            "予測:  sports-watch\n",
            "正解:  movie-enter\n",
            "かわいいパンダ写真37枚、仕事の合間に見て癒される\n",
            "予測:  sports-watch\n",
            "正解:  movie-enter\n",
            "乃木坂46ではデジカメがブーム？「1000メディア出演キャラバン」でメンバーに聞く\n",
            "予測:  sports-watch\n",
            "正解:  it-life-hack\n",
            "峰不二子に勝るとも劣らない、スタイル抜群の“イイ女”が映画デビュー\n",
            "予測:  sports-watch\n",
            "正解:  movie-enter\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ELv8w75i2-0E",
        "colab_type": "code",
        "outputId": "b74da2f0-0f57-4bcc-b979-11bab719429e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "test1 = encoder.encode('\tZOZO前澤友作社長による話題集め 社員のモチベーションには悪影響？')\n",
        "test1 = np.array(test1).reshape(-1, 100)\n",
        "test1_pred = model.predict(test1)\n",
        "category_dirs[np.argmax(test1_pred, axis=1)[0]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'it-life-hack'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "metadata": {
        "id": "-xStV2HM4UBe",
        "colab_type": "code",
        "outputId": "ea88ac90-e132-4c33-f237-2150c4ff5ae7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "test2 = encoder.encode('日本は「恥ずかしいベスト16進出」オマーン戦を韓国紙が酷評')\n",
        "test2 = np.array(test2).reshape(-1, 100)\n",
        "test2_pred = model.predict(test2)\n",
        "category_dirs[np.argmax(test2_pred, axis=1)[0]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sports-watch'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "metadata": {
        "id": "ocpmd-iQ4w_-",
        "colab_type": "code",
        "outputId": "c9af3dbb-3af4-451c-959c-b278c366daa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "test3 = encoder.encode('シャルレーヌ公妃激白！愛らしすぎる双子の逸話と写真が大反響')\n",
        "test3 = np.array(test3).reshape(-1, 100)\n",
        "test3_pred = model.predict(test3)\n",
        "category_dirs[np.argmax(test3_pred, axis=1)[0]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'movie-enter'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "metadata": {
        "id": "d8eEEvm_-INZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('LSTM-classifier.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A3u4rLW2slk3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### GRU\n",
        "- 2014年に考案。\n",
        "- LSTMと比べてパラメータが少なく、計算時間が短縮できる。\n",
        "- 記憶セルを必要としない。\n",
        "- resetゲート$\\bf r$\n",
        "  - 過去の隠れ状態をどれだけ無視するかを決定\n",
        "  - $\\bf r$が0であれば新しい隠れ状態は入力$\\bf x_t$のみから決定\n",
        "- updateゲート$\\bf z$\n",
        "  - 隠れ状態を更新\n",
        "  - LSTMのforgetゲート、inputゲートに相当"
      ]
    },
    {
      "metadata": {
        "id": "YgkI2MmH96ZK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### GRUで文章分類\n",
        "- このタスクに関してはGRUの方が早く学習が進んでいる。\n",
        "- データセットが十分小さい時はGRUのほうが適している。"
      ]
    },
    {
      "metadata": {
        "id": "IX8PkTRN943i",
        "colab_type": "code",
        "outputId": "3a29d061-9e66-4deb-bdb8-9ea815a006a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, GRU, Dense, Dropout\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "embedding_matrix = np.zeros((len(encoder.word2id), 100))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(\n",
        "        input_dim=embedding_matrix.shape[0], \n",
        "        output_dim=embedding_matrix.shape[1],\n",
        "        mask_zero=True))\n",
        "model.add(GRU(32, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(GRU(32))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32,validation_data=(x_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_33 (Embedding)     (None, None, 100)         794500    \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, None, 32)          12768     \n",
            "_________________________________________________________________\n",
            "dropout_34 (Dropout)         (None, None, 32)          0         \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 32)                6240      \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 813,607\n",
            "Trainable params: 813,607\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 2114 samples, validate on 529 samples\n",
            "Epoch 1/10\n",
            "2114/2114 [==============================] - 34s 16ms/step - loss: 0.9001 - acc: 0.6008 - val_loss: 0.5037 - val_acc: 0.7826\n",
            "Epoch 2/10\n",
            "2114/2114 [==============================] - 28s 13ms/step - loss: 0.2078 - acc: 0.9253 - val_loss: 0.2053 - val_acc: 0.9376\n",
            "Epoch 3/10\n",
            "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0281 - acc: 0.9957 - val_loss: 0.1859 - val_acc: 0.9471\n",
            "Epoch 4/10\n",
            "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0073 - acc: 0.9995 - val_loss: 0.2256 - val_acc: 0.9433\n",
            "Epoch 5/10\n",
            "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0074 - acc: 0.9995 - val_loss: 0.2305 - val_acc: 0.9471\n",
            "Epoch 6/10\n",
            "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0057 - acc: 0.9995 - val_loss: 0.2250 - val_acc: 0.9509\n",
            "Epoch 7/10\n",
            "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0038 - acc: 0.9995 - val_loss: 0.2272 - val_acc: 0.9509\n",
            "Epoch 8/10\n",
            "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0052 - acc: 0.9991 - val_loss: 0.2984 - val_acc: 0.9376\n",
            "Epoch 9/10\n",
            "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0038 - acc: 0.9995 - val_loss: 0.3321 - val_acc: 0.9319\n",
            "Epoch 10/10\n",
            "2114/2114 [==============================] - 28s 13ms/step - loss: 0.0050 - acc: 0.9995 - val_loss: 0.3262 - val_acc: 0.9357\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4230963f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "metadata": {
        "id": "fVgSyTgmc2Ws",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 言語モデルの評価\n",
        "- **Perplexity**が指標としてよく用いられる\n",
        "  - 確率の逆数\n",
        "  - 例：\"you say goodbye and I say hello\"がコーパスで入力データ数=1の場合\n",
        "    - \"you\"をモデル1に与えて次の単語が\"say\"がである確率が0.8であると出力\n",
        "      - perplexityは$\\frac{1}{0.8}=1.25$ => 良い予測\n",
        "    - \"you\"をモデル2に与えて次の単語が\"say\"がである確率が0.2であると出力\n",
        "      - perplexityは$\\frac{1}{0.2}=5$ => 悪い予測\n",
        "  - 直感的には「分岐数」と解釈\n",
        "      - モデル１は次候補が1程度で絞りきれている\n",
        "      - モデル2は次候補が5つもあって絞りきれていない\n",
        "  - 入力データ複数の場合\n",
        "    - $$\n",
        "    \\begin{eqnarray}\n",
        "    L = -\\frac{1}{N}\\sum^{}_{n}\\sum^{}_{k}t_{nk}\\log{y_{nk}}\\\\\n",
        "    perplexity =e^{L}\n",
        "    \\end{eqnarray}\n",
        "    $$\n",
        "    $\\bf t_n$ : one-hotベクトルの正解ラベル\n",
        "    \n",
        "      $y_n$ : 確率分布\n",
        "  - 実装してるフレームワークはあまりなさそう。https://qiita.com/HotAllure/items/9f58cf7feb3053124216\n",
        "      　\n"
      ]
    },
    {
      "metadata": {
        "id": "B76GtlhCQiv3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## RNN特有の性質\n",
        "- MLPやCNNは入力と出力のテンソルのサイズが固定されている。\n",
        "- RNNは入力と出力に系列を与えることができるので、様々な入出力パターンが考えられる\n",
        "  - 一対一\n",
        "    - 例：文字レベル単語生成RNN（上の実装）\n",
        "  - 多対多\n",
        "    - 例：機械翻訳(Seq2seq)\n",
        "  - 一対多\n",
        "    - 例：画像キャプション\n",
        "  - 多対一\n",
        "    - 例：評判分析\n",
        "- 前の時刻のデータを逐一利用しているので並列処理が出来ない部分がある\n",
        "  - 近年ではできるだけRNNを避けようとする動きがある\n",
        "    \n",
        "  "
      ]
    },
    {
      "metadata": {
        "id": "xv6g055TzOa2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## seq2seq\n",
        "- https://google.github.io/seq2seq/\n",
        "- 時系列 => 時系列に変換\n",
        "- 2つのRNNを利用\n",
        "  - Encoder-Decoderモデルとも呼ばれる\n",
        "  - Encoderから隠れ状態$\\bf h$出力\n",
        "    - 任意の長さの文章を固定長のベクトルに変換\n",
        "  - Decoderが時刻0で$\\bf h$を受け取る（通常０ベクトルを受け取る）、結果を出力\n",
        "- 改良\n",
        "  - 入力データの反転(reverse)\n",
        "    - 逆伝搬がスムーズになる\n",
        "  - 覗き見(peeky)\n",
        "    - Encoderからの隠れベクトル$/bf h$をDecoderの最初の時刻のLSTMレイヤ以外にも入力する\n",
        " - 応用\n",
        "    - 機械翻訳\n",
        "    - 自動要約\n",
        "    - 質疑応答（チャットボット）\n",
        "    - 自動返信\n",
        "    - アルゴリズムの学習\n",
        "    - イメージキャプション\n",
        "     - EncoderをCNNに変える\n",
        "     - 特徴マップを平らにして全結合層によって変換してDecoderに渡す\n",
        "     - im2txt\n"
      ]
    },
    {
      "metadata": {
        "id": "jQb2nxqvJS2l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 足し算の学習\n",
        "- kerasでは融通がきかないので、(Embedding層を追加したいときなど)Tensorflow, Pytorchなどで実装した方が良さそう。"
      ]
    },
    {
      "metadata": {
        "id": "fXU7TxHTJMaY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "データの準備\n",
        "\n",
        "'''\n",
        "import numpy as np\n",
        "\n",
        "# 数字生成\n",
        "def n(digits=3):\n",
        "  number = ''\n",
        "  for i in range(np.random.randint(1, digits + 1)):\n",
        "    number += np.random.choice(list('0123456789'))\n",
        "  return int(number)\n",
        "\n",
        "# パディング\n",
        "def padding(chars, maxlen):\n",
        "  return chars + ' ' * (maxlen - len(chars))\n",
        "\n",
        "digits = 3\n",
        "input_digits = digits * 2 + 1 # 3桁２つと「+」一つ\n",
        "output_digits = digits + 1# 500 + 500 = 1000以上で4桁\n",
        "\n",
        "N = 20000\n",
        "added = set()\n",
        "questions = []\n",
        "answers = []\n",
        "\n",
        "while len(questions) < N:\n",
        "  a, b = n(), n()\n",
        "  \n",
        "  pair = tuple(sorted((a, b)))\n",
        "  if pair in added:\n",
        "    continue\n",
        "  \n",
        "  question = '{}+{}'.format(a, b)\n",
        "  question = padding(question, input_digits)\n",
        "  answer = str(a + b)\n",
        "  answer = padding(answer, output_digits)\n",
        "  \n",
        "  added.add(pair)\n",
        "  questions.append(question)\n",
        "  answers.append(answer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AMdXaq0VJRUY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "chars = '0123456789+ '\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O7zCOB3mMdUg",
        "colab_type": "code",
        "outputId": "a847b755-2dd2-4fe7-fd20-5970beccfeee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# one-hot encoding\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = np.zeros((len(questions), input_digits, len(chars)), dtype=np.int)\n",
        "Y = np.zeros((len(questions), digits + 1, len(chars)))\n",
        "\n",
        "for i in range(N):\n",
        "  for t, char in enumerate(questions[i]):\n",
        "    X[i, t, char_indices[char]] = 1\n",
        "  for t, char in enumerate(answers[i]):\n",
        "    Y[i, t, char_indices[char]] = 1\n",
        "\n",
        "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, train_size=0.8)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "JnWLsqRvOIFv",
        "colab_type": "code",
        "outputId": "c13c5cd0-ac1d-4ef7-de94-ed5df2f377a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1751
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,  LSTM\n",
        "\n",
        "from keras.layers.core import RepeatVector\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "\n",
        "# Encoder\n",
        "model = Sequential()\n",
        "model.add(LSTM(32, input_shape=(input_digits, len(chars))))\n",
        "\n",
        "# Decoder\n",
        "model.add(RepeatVector(output_digits)) # peeky\n",
        "model.add(LSTM(32, return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(len(chars), activation='softmax')))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, Y_train, epochs=50, batch_size=32, validation_data=(X_validation, Y_validation))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 16000 samples, validate on 4000 samples\n",
            "Epoch 1/50\n",
            "16000/16000 [==============================] - 24s 1ms/step - loss: 1.9113 - acc: 0.3257 - val_loss: 1.8014 - val_acc: 0.3493\n",
            "Epoch 2/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.7878 - acc: 0.3531 - val_loss: 1.7734 - val_acc: 0.3544\n",
            "Epoch 3/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.7663 - acc: 0.3595 - val_loss: 1.7690 - val_acc: 0.3548\n",
            "Epoch 4/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.7507 - acc: 0.3606 - val_loss: 1.7408 - val_acc: 0.3611\n",
            "Epoch 5/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.7274 - acc: 0.3695 - val_loss: 1.7170 - val_acc: 0.3706\n",
            "Epoch 6/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.7013 - acc: 0.3756 - val_loss: 1.6881 - val_acc: 0.3725\n",
            "Epoch 7/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.6630 - acc: 0.3836 - val_loss: 1.6526 - val_acc: 0.3835\n",
            "Epoch 8/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.6221 - acc: 0.3969 - val_loss: 1.6165 - val_acc: 0.4010\n",
            "Epoch 9/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.5834 - acc: 0.4151 - val_loss: 1.5617 - val_acc: 0.4209\n",
            "Epoch 10/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.5329 - acc: 0.4351 - val_loss: 1.5113 - val_acc: 0.4454\n",
            "Epoch 11/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.4855 - acc: 0.4530 - val_loss: 1.4712 - val_acc: 0.4591\n",
            "Epoch 12/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.4375 - acc: 0.4683 - val_loss: 1.4204 - val_acc: 0.4692\n",
            "Epoch 13/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.3988 - acc: 0.4821 - val_loss: 1.3869 - val_acc: 0.4815\n",
            "Epoch 14/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.3603 - acc: 0.4948 - val_loss: 1.3587 - val_acc: 0.4881\n",
            "Epoch 15/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.3294 - acc: 0.5035 - val_loss: 1.3252 - val_acc: 0.4969\n",
            "Epoch 16/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.2970 - acc: 0.5145 - val_loss: 1.3423 - val_acc: 0.4930\n",
            "Epoch 17/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.2701 - acc: 0.5264 - val_loss: 1.2702 - val_acc: 0.5211\n",
            "Epoch 18/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.2452 - acc: 0.5346 - val_loss: 1.2687 - val_acc: 0.5162\n",
            "Epoch 19/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.2232 - acc: 0.5418 - val_loss: 1.2248 - val_acc: 0.5401\n",
            "Epoch 20/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.2019 - acc: 0.5506 - val_loss: 1.2066 - val_acc: 0.5444\n",
            "Epoch 21/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.1815 - acc: 0.5583 - val_loss: 1.1948 - val_acc: 0.5512\n",
            "Epoch 22/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.1652 - acc: 0.5634 - val_loss: 1.1825 - val_acc: 0.5526\n",
            "Epoch 23/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.1482 - acc: 0.5696 - val_loss: 1.1769 - val_acc: 0.5528\n",
            "Epoch 24/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.1324 - acc: 0.5749 - val_loss: 1.1505 - val_acc: 0.5622\n",
            "Epoch 25/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.1196 - acc: 0.5779 - val_loss: 1.1364 - val_acc: 0.5664\n",
            "Epoch 26/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.1061 - acc: 0.5825 - val_loss: 1.1152 - val_acc: 0.5739\n",
            "Epoch 27/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.0929 - acc: 0.5880 - val_loss: 1.1082 - val_acc: 0.5777\n",
            "Epoch 28/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.0807 - acc: 0.5932 - val_loss: 1.1056 - val_acc: 0.5759\n",
            "Epoch 29/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.0717 - acc: 0.5967 - val_loss: 1.0928 - val_acc: 0.5804\n",
            "Epoch 30/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.0619 - acc: 0.5988 - val_loss: 1.0745 - val_acc: 0.5890\n",
            "Epoch 31/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.0508 - acc: 0.6027 - val_loss: 1.0735 - val_acc: 0.5880\n",
            "Epoch 32/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.0416 - acc: 0.6070 - val_loss: 1.0610 - val_acc: 0.5942\n",
            "Epoch 33/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.0336 - acc: 0.6102 - val_loss: 1.0589 - val_acc: 0.5959\n",
            "Epoch 34/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.0249 - acc: 0.6130 - val_loss: 1.0413 - val_acc: 0.6007\n",
            "Epoch 35/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.0163 - acc: 0.6181 - val_loss: 1.0370 - val_acc: 0.6061\n",
            "Epoch 36/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.0073 - acc: 0.6217 - val_loss: 1.0331 - val_acc: 0.6044\n",
            "Epoch 37/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.0015 - acc: 0.6224 - val_loss: 1.0241 - val_acc: 0.6067\n",
            "Epoch 38/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.9938 - acc: 0.6266 - val_loss: 1.0160 - val_acc: 0.6111\n",
            "Epoch 39/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.9895 - acc: 0.6274 - val_loss: 1.0155 - val_acc: 0.6102\n",
            "Epoch 40/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.9808 - acc: 0.6313 - val_loss: 1.0124 - val_acc: 0.6119\n",
            "Epoch 41/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.9735 - acc: 0.6327 - val_loss: 1.0035 - val_acc: 0.6157\n",
            "Epoch 42/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.9668 - acc: 0.6367 - val_loss: 0.9971 - val_acc: 0.6179\n",
            "Epoch 43/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.9615 - acc: 0.6371 - val_loss: 0.9886 - val_acc: 0.6248\n",
            "Epoch 44/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.9574 - acc: 0.6382 - val_loss: 0.9798 - val_acc: 0.6261\n",
            "Epoch 45/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.9491 - acc: 0.6422 - val_loss: 0.9974 - val_acc: 0.6212\n",
            "Epoch 46/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.9443 - acc: 0.6440 - val_loss: 0.9793 - val_acc: 0.6261\n",
            "Epoch 47/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.9376 - acc: 0.6465 - val_loss: 0.9781 - val_acc: 0.6278\n",
            "Epoch 48/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.9335 - acc: 0.6485 - val_loss: 0.9638 - val_acc: 0.6322\n",
            "Epoch 49/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.9289 - acc: 0.6508 - val_loss: 0.9746 - val_acc: 0.6261\n",
            "Epoch 50/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.9242 - acc: 0.6505 - val_loss: 0.9751 - val_acc: 0.6311\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f422cc18d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "metadata": {
        "id": "2iuqKHgnax-H",
        "colab_type": "code",
        "outputId": "1bb0b78a-dcad-451f-86c4-c108f5f49d4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1751
        }
      },
      "cell_type": "code",
      "source": [
        "# 入力データの反転\n",
        "\n",
        "X_train_reverse = X_train[:, ::-1, :]\n",
        "X_validation_reverse = X_validation[:, ::-1, :]\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,  LSTM\n",
        "\n",
        "from keras.layers.core import RepeatVector\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "\n",
        "# Encoder\n",
        "model = Sequential()\n",
        "model.add(LSTM(32, input_shape=(input_digits, len(chars))))\n",
        "\n",
        "# Decoder\n",
        "model.add(RepeatVector(output_digits)) # peeky\n",
        "model.add(LSTM(32, return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(len(chars), activation='softmax')))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_reverse, Y_train, epochs=50, batch_size=32, validation_data=(X_validation_reverse, Y_validation))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 16000 samples, validate on 4000 samples\n",
            "Epoch 1/50\n",
            "16000/16000 [==============================] - 26s 2ms/step - loss: 1.9132 - acc: 0.3256 - val_loss: 1.7865 - val_acc: 0.3509\n",
            "Epoch 2/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.7800 - acc: 0.3559 - val_loss: 1.7611 - val_acc: 0.3588\n",
            "Epoch 3/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.7568 - acc: 0.3597 - val_loss: 1.7381 - val_acc: 0.3618\n",
            "Epoch 4/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.7280 - acc: 0.3684 - val_loss: 1.7120 - val_acc: 0.3661\n",
            "Epoch 5/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.6911 - acc: 0.3767 - val_loss: 1.6799 - val_acc: 0.3722\n",
            "Epoch 6/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.6575 - acc: 0.3869 - val_loss: 1.6479 - val_acc: 0.3899\n",
            "Epoch 7/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.6234 - acc: 0.3998 - val_loss: 1.6152 - val_acc: 0.4028\n",
            "Epoch 8/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.5750 - acc: 0.4193 - val_loss: 1.5495 - val_acc: 0.4302\n",
            "Epoch 9/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.5060 - acc: 0.4444 - val_loss: 1.4719 - val_acc: 0.4534\n",
            "Epoch 10/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.4386 - acc: 0.4646 - val_loss: 1.4137 - val_acc: 0.4672\n",
            "Epoch 11/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.3825 - acc: 0.4796 - val_loss: 1.3750 - val_acc: 0.4796\n",
            "Epoch 12/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.3370 - acc: 0.4939 - val_loss: 1.3218 - val_acc: 0.4944\n",
            "Epoch 13/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.2972 - acc: 0.5085 - val_loss: 1.2863 - val_acc: 0.5046\n",
            "Epoch 14/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.2608 - acc: 0.5253 - val_loss: 1.2503 - val_acc: 0.5262\n",
            "Epoch 15/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.2292 - acc: 0.5374 - val_loss: 1.2254 - val_acc: 0.5377\n",
            "Epoch 16/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.2013 - acc: 0.5495 - val_loss: 1.2014 - val_acc: 0.5485\n",
            "Epoch 17/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.1747 - acc: 0.5618 - val_loss: 1.1754 - val_acc: 0.5567\n",
            "Epoch 18/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.1509 - acc: 0.5721 - val_loss: 1.1582 - val_acc: 0.5629\n",
            "Epoch 19/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.1297 - acc: 0.5803 - val_loss: 1.1374 - val_acc: 0.5698\n",
            "Epoch 20/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.1090 - acc: 0.5892 - val_loss: 1.1202 - val_acc: 0.5767\n",
            "Epoch 21/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.0908 - acc: 0.5976 - val_loss: 1.1028 - val_acc: 0.5847\n",
            "Epoch 22/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.0743 - acc: 0.6030 - val_loss: 1.0819 - val_acc: 0.5968\n",
            "Epoch 23/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.0583 - acc: 0.6101 - val_loss: 1.0718 - val_acc: 0.5961\n",
            "Epoch 24/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.0431 - acc: 0.6168 - val_loss: 1.0562 - val_acc: 0.6065\n",
            "Epoch 25/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.0286 - acc: 0.6212 - val_loss: 1.0543 - val_acc: 0.6028\n",
            "Epoch 26/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.0159 - acc: 0.6277 - val_loss: 1.0314 - val_acc: 0.6150\n",
            "Epoch 27/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 1.0039 - acc: 0.6296 - val_loss: 1.0286 - val_acc: 0.6174\n",
            "Epoch 28/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.9920 - acc: 0.6352 - val_loss: 1.0087 - val_acc: 0.6254\n",
            "Epoch 29/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.9820 - acc: 0.6391 - val_loss: 1.0034 - val_acc: 0.6233\n",
            "Epoch 30/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.9702 - acc: 0.6430 - val_loss: 0.9904 - val_acc: 0.6298\n",
            "Epoch 31/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.9597 - acc: 0.6468 - val_loss: 0.9811 - val_acc: 0.6334\n",
            "Epoch 32/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.9491 - acc: 0.6500 - val_loss: 0.9663 - val_acc: 0.6424\n",
            "Epoch 33/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.9398 - acc: 0.6560 - val_loss: 0.9555 - val_acc: 0.6430\n",
            "Epoch 34/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.9324 - acc: 0.6565 - val_loss: 0.9603 - val_acc: 0.6413\n",
            "Epoch 35/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.9235 - acc: 0.6611 - val_loss: 0.9400 - val_acc: 0.6516\n",
            "Epoch 36/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.9158 - acc: 0.6638 - val_loss: 0.9498 - val_acc: 0.6439\n",
            "Epoch 37/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.9082 - acc: 0.6682 - val_loss: 0.9320 - val_acc: 0.6522\n",
            "Epoch 38/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.9029 - acc: 0.6682 - val_loss: 0.9308 - val_acc: 0.6487\n",
            "Epoch 39/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.8950 - acc: 0.6712 - val_loss: 0.9164 - val_acc: 0.6562\n",
            "Epoch 40/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.8892 - acc: 0.6746 - val_loss: 0.9140 - val_acc: 0.6624\n",
            "Epoch 41/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.8815 - acc: 0.6770 - val_loss: 0.9042 - val_acc: 0.6630\n",
            "Epoch 42/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.8753 - acc: 0.6774 - val_loss: 0.9046 - val_acc: 0.6613\n",
            "Epoch 43/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.8706 - acc: 0.6804 - val_loss: 0.8948 - val_acc: 0.6666\n",
            "Epoch 44/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.8647 - acc: 0.6825 - val_loss: 0.8900 - val_acc: 0.6680\n",
            "Epoch 45/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.8598 - acc: 0.6844 - val_loss: 0.8929 - val_acc: 0.6694\n",
            "Epoch 46/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.8555 - acc: 0.6867 - val_loss: 0.8914 - val_acc: 0.6638\n",
            "Epoch 47/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.8487 - acc: 0.6892 - val_loss: 0.8911 - val_acc: 0.6653\n",
            "Epoch 48/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.8440 - acc: 0.6903 - val_loss: 0.8727 - val_acc: 0.6755\n",
            "Epoch 49/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.8407 - acc: 0.6921 - val_loss: 0.8717 - val_acc: 0.6743\n",
            "Epoch 50/50\n",
            "16000/16000 [==============================] - 17s 1ms/step - loss: 0.8353 - acc: 0.6939 - val_loss: 0.8644 - val_acc: 0.6787\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4227412be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "metadata": {
        "id": "sTkyHGWsals_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Attention\n",
        "- seq2seqではEncoderから「固定長のベクトル」しか出力されない\n",
        "  - 入力文の長さが反映されない\n",
        "- EncoderのLSTMレイヤの隠れ状態ベクトルを全て利用\n",
        "  - 入力された単語列の数に応じて隠れ状態ベクトルの大きさが変わる\n",
        "  - 各単語に対応したベクトルの集合$\\bf h_s$が得られる\n",
        "- Decoderへの入力単語と対応関係にある単語のベクトルを$\\bf h_s$から選び出す\n",
        "  - 「選ぶ」という操作は微分不可 => 逆伝搬できない\n",
        "- 各単語の重要度を利用して、隠れベクトルの重みつき和を求める => コンテキストベクトル\n",
        "- 重要度はencoderからの各隠れベクトルとDecoderからの隠れベクトルの内積をとって算出\n",
        "  - 最終的にはSoftmaxで正規化\n",
        "- Attentionを使った最先端のモデル\n",
        "  - Google Neural Machine Translation(GNMT)\n",
        "    - Google翻訳\n",
        "    - 大量の計算リソースが必要（GPU100枚で6日）\n",
        "  - Transformer\n",
        "    - RNNを使わない => AttentionはRNNを置き換えるモジュールとして使える\n",
        "    - GNMTよりも精度が高い\n",
        "    - 学習時間をGNMTと比べて大幅に削減\n",
        "  - Neural Turing Machine(NTM)\n",
        "    - Encoder => Attention => Decoderをメモリ操作\n",
        "    - 発展形：Differentiable Neural Computers (DNC)\n",
        "- Pytorch Tutorialに実装あります  https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
        "    \n",
        "    "
      ]
    },
    {
      "metadata": {
        "id": "SG2xZ_2-KwXK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Attentionの実装（Pytorch）"
      ]
    },
    {
      "metadata": {
        "id": "Tv8HGqW_Kv0-",
        "colab_type": "code",
        "outputId": "84a716fe-5088-41d2-c548-b46269c271e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install torch torchvision"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/60/66415660aa46b23b5e1b72bc762e816736ce8d7260213e22365af51e8f9c/torch-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (591.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 591.8MB 24kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x6265c000 @  0x7fdb178af2a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "\u001b[?25hCollecting torchvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 20.4MB/s \n",
            "\u001b[?25hCollecting pillow>=4.1.1 (from torchvision)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/5e/e91792f198bbc5a0d7d3055ad552bc4062942d27eaf75c3e2783cf64eae5/Pillow-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.0MB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Installing collected packages: torch, pillow, torchvision\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.4.1 torch-1.0.0 torchvision-0.2.1\n",
            "\u001b[0;31;1mWARNING: The following packages were previously imported in this runtime:\n",
            "  [PIL]\n",
            "You must restart the runtime in order to use newly installed versions.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9iteN5E0LWrG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QlJP6GV7MARU",
        "colab_type": "code",
        "outputId": "dac7e14f-b1ac-4917-8855-e249c4327c11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "cell_type": "code",
      "source": [
        "!wget https://download.pytorch.org/tutorial/data.zip\n",
        "!mv data.zip seq2seq_data.zip\n",
        "!unzip seq2seq_data.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-16 01:00:16--  https://download.pytorch.org/tutorial/data.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 99.84.194.32, 99.84.194.47, 99.84.194.68, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|99.84.194.32|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2882130 (2.7M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]   2.75M  4.21MB/s    in 0.7s    \n",
            "\n",
            "2019-01-16 01:00:17 (4.21 MB/s) - ‘data.zip’ saved [2882130/2882130]\n",
            "\n",
            "Archive:  seq2seq_data.zip\n",
            "  inflating: data/eng-fra.txt        \n",
            "   creating: data/names/\n",
            "  inflating: data/names/Arabic.txt   \n",
            "  inflating: data/names/Chinese.txt  \n",
            "  inflating: data/names/Czech.txt    \n",
            "  inflating: data/names/Dutch.txt    \n",
            "  inflating: data/names/English.txt  \n",
            "  inflating: data/names/French.txt   \n",
            "  inflating: data/names/German.txt   \n",
            "  inflating: data/names/Greek.txt    \n",
            "  inflating: data/names/Irish.txt    \n",
            "  inflating: data/names/Italian.txt  \n",
            "  inflating: data/names/Japanese.txt  \n",
            "  inflating: data/names/Korean.txt   \n",
            "  inflating: data/names/Polish.txt   \n",
            "  inflating: data/names/Portuguese.txt  \n",
            "  inflating: data/names/Russian.txt  \n",
            "  inflating: data/names/Scottish.txt  \n",
            "  inflating: data/names/Spanish.txt  \n",
            "  inflating: data/names/Vietnamese.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Cd706g7oQY6s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XGmGAClyLJus",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 各言語をまとめるhelper class\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TFtkxYTdMmNM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vd8WGU7_M3al",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 翻訳文のペア作成。逆翻訳もできるように逆順ペアも作れるようにする\n",
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs] # reversedは要素を逆順に返すイテレータを返す\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rp4J5hZjN1Rd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 最大10単語、代名詞+be動詞現在形始まりのみ抽出\n",
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bc0XK_k5O9VU",
        "colab_type": "code",
        "outputId": "04c0f230-5ab7-4b71-ca9d-efc9c3f141cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "# 前処理の一連の流れ：\n",
        "# 1. テキストファイル読み込み\n",
        "# 2. 列ごとにsplit\n",
        "# 3. ペアをsplit、リストに格納\n",
        "# 4. 正規化、長さと内容のフィルタリング\n",
        "# 5. 各言語ごとに文章を格納（Langクラスのインスタンス）\n",
        "\n",
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 10599 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "fra 4345\n",
            "eng 2803\n",
            "['c est une beaute .', 'she is a beauty .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W6Z8lxljQahF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Encoder\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2TfscAo5SPW1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Simple Decoder（Encoderの最後の出力がDecoderの初期の隠れベクトルになる）\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D3uZF_2NTWDd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VYVjHj9hWIVN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 訓練データの準備\n",
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7tirCfcYWLFt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "teacher_forcing_ratio = 0.5 # Decoderへ入力する回数の割合\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GpqoFZXiZcE9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5BfRiSiTZf0t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss() #　負の対数尤度\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B6HaKtjEbBNd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ION7I-CkbBpm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XXFa0iqrbLeu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 訓練データからランダムに推論して主観評価\n",
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5sPP8SbPbXDG",
        "colab_type": "code",
        "outputId": "2a414b28-94a0-4bc5-96aa-cbe2ef27f888",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2m 19s (- 32m 34s) (5000 6%) 2.8779\n",
            "4m 34s (- 29m 41s) (10000 13%) 2.2621\n",
            "6m 49s (- 27m 18s) (15000 20%) 1.9397\n",
            "9m 5s (- 24m 59s) (20000 26%) 1.6973\n",
            "11m 22s (- 22m 44s) (25000 33%) 1.5276\n",
            "13m 39s (- 20m 28s) (30000 40%) 1.3366\n",
            "15m 55s (- 18m 11s) (35000 46%) 1.2127\n",
            "18m 10s (- 15m 54s) (40000 53%) 1.0497\n",
            "20m 26s (- 13m 37s) (45000 60%) 0.9702\n",
            "22m 44s (- 11m 22s) (50000 66%) 0.8639\n",
            "25m 1s (- 9m 5s) (55000 73%) 0.7680\n",
            "27m 18s (- 6m 49s) (60000 80%) 0.7342\n",
            "29m 35s (- 4m 33s) (65000 86%) 0.6588\n",
            "31m 53s (- 2m 16s) (70000 93%) 0.6143\n",
            "34m 11s (- 0m 0s) (75000 100%) 0.5387\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "18CWJlZmbc3t",
        "colab_type": "code",
        "outputId": "7039352f-99d6-4ebf-fd6c-97293f7f3181",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "cell_type": "code",
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> nous sommes tristes .\n",
            "= we re sad .\n",
            "< we re crazy . <EOS>\n",
            "\n",
            "> nous en avons fini ici .\n",
            "= we re finished here .\n",
            "< we re finished here . <EOS>\n",
            "\n",
            "> nous sommes journalistes .\n",
            "= we re journalists .\n",
            "< we re divorced . <EOS>\n",
            "\n",
            "> vous etes fort genereuse .\n",
            "= you re very generous .\n",
            "< you re very generous . <EOS>\n",
            "\n",
            "> vous etes fort elegant .\n",
            "= you re very sophisticated .\n",
            "< you re very stylish . <EOS>\n",
            "\n",
            "> vous n etes pas des notres .\n",
            "= you re not one of us .\n",
            "< you re not one of us . <EOS>\n",
            "\n",
            "> je suis en vacances .\n",
            "= i m on holiday .\n",
            "< i m on vacation . <EOS>\n",
            "\n",
            "> il n est pas vraiment minutieux .\n",
            "= he s not a very meticulous guy .\n",
            "< he s not a very meticulous . <EOS>\n",
            "\n",
            "> c est une bonne nageuse .\n",
            "= she is a good swimmer .\n",
            "< she is a good swimmer . <EOS>\n",
            "\n",
            "> il est cruel et sans c ur .\n",
            "= he s cruel and heartless .\n",
            "< he s cruel and . <EOS>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YOORjR3gjrka",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}